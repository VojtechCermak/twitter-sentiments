{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = ['lemmas', 'tokens']\n",
    "aggregates = ['hour', '5min', 'min', 'none']\n",
    "\n",
    "#labels\n",
    "directions = ['past', 'future']\n",
    "windows = [60, 1]\n",
    "\n",
    "embeddings = ['Twitter_200D', 'GoogleNews_300D', 'Wikipedia_300D']\n",
    "#WV_vectorizers = ['mean', 'mean_sw', 'minmax', 'idf', 'idf_sw']\n",
    "WV_vectorizers = ['mean', 'mean_sw', 'idf', 'idf_sw']\n",
    "BOW_vectorizers = ['binary', 'count', 'count_sw', 'frequency', 'tfidf', 'tfidf_sw', 'log_tfidf', 'log_tfidf_sw']\n",
    "\n",
    "# validation\n",
    "models = ['L2_logit', 'L1_logit', 'nb']\n",
    "metrics = ['kappa', 'acc']\n",
    "\n",
    "inputDict = {'forms':forms, 'aggregates':aggregates, 'directions':directions, 'windows':windows, \n",
    "             'BOW_vectorizers':BOW_vectorizers, 'WV_vectorizers':WV_vectorizers, 'embeddings':embeddings,\n",
    "             'models':models, 'metrics':metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Features(inputDict)\n",
    "f.embedding_path = {'Twitter_200D':'N:\\\\diplomka temp\\\\word2vec\\\\glove.twitter.27B.200d.txt',\n",
    "                    'GoogleNews_300D': 'N:\\\\diplomka temp\\\\word2vec\\\\GoogleNews-vectors-negative300.bin',\n",
    "                    'Wikipedia_300D':'N:\\\\diplomka temp\\\\word2vec\\\\glove.840B.300d.txt'}\n",
    "f.price_path = 'N:\\\\diplomka temp\\\\dataMarket\\\\GOOG1min.csv'\n",
    "f.tweets_path = 'N:\\\\diplomka temp\\\\dataProcessed\\\\tweetsGOOG.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f.load_data()\n",
    "#f.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating: ('lemmas', 'hour')\n",
      "Aggregating: ('lemmas', '5min')\n",
      "Aggregating: ('lemmas', 'min')\n",
      "Aggregating: ('lemmas', 'none')\n",
      "Aggregating: ('tokens', 'hour')\n",
      "Aggregating: ('tokens', '5min')\n",
      "Aggregating: ('tokens', 'min')\n",
      "Aggregating: ('tokens', 'none')\n",
      "Wall time: 49min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f.create_corpuses()\n",
    "del f.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lemmas', 'hour', 'Twitter_200D', 'mean')\n",
      "('lemmas', 'hour', 'Twitter_200D', 'mean_sw')\n",
      "('lemmas', 'hour', 'Twitter_200D', 'idf')\n",
      "('lemmas', 'hour', 'Twitter_200D', 'idf_sw')\n",
      "('lemmas', 'hour', 'GoogleNews_300D', 'mean')\n",
      "('lemmas', 'hour', 'GoogleNews_300D', 'mean_sw')\n",
      "('lemmas', 'hour', 'GoogleNews_300D', 'idf')\n",
      "('lemmas', 'hour', 'GoogleNews_300D', 'idf_sw')\n",
      "('lemmas', 'hour', 'Wikipedia_300D', 'mean')\n",
      "('lemmas', 'hour', 'Wikipedia_300D', 'mean_sw')\n",
      "('lemmas', 'hour', 'Wikipedia_300D', 'idf')\n",
      "('lemmas', 'hour', 'Wikipedia_300D', 'idf_sw')\n",
      "('lemmas', '5min', 'Twitter_200D', 'mean')\n",
      "('lemmas', '5min', 'Twitter_200D', 'mean_sw')\n",
      "('lemmas', '5min', 'Twitter_200D', 'idf')\n",
      "('lemmas', '5min', 'Twitter_200D', 'idf_sw')\n",
      "('lemmas', '5min', 'GoogleNews_300D', 'mean')\n",
      "('lemmas', '5min', 'GoogleNews_300D', 'mean_sw')\n",
      "('lemmas', '5min', 'GoogleNews_300D', 'idf')\n",
      "('lemmas', '5min', 'GoogleNews_300D', 'idf_sw')\n",
      "('lemmas', '5min', 'Wikipedia_300D', 'mean')\n",
      "('lemmas', '5min', 'Wikipedia_300D', 'mean_sw')\n",
      "('lemmas', '5min', 'Wikipedia_300D', 'idf')\n",
      "('lemmas', '5min', 'Wikipedia_300D', 'idf_sw')\n",
      "('lemmas', 'min', 'Twitter_200D', 'mean')\n",
      "('lemmas', 'min', 'Twitter_200D', 'mean_sw')\n",
      "('lemmas', 'min', 'Twitter_200D', 'idf')\n",
      "('lemmas', 'min', 'Twitter_200D', 'idf_sw')\n",
      "('lemmas', 'min', 'GoogleNews_300D', 'mean')\n",
      "('lemmas', 'min', 'GoogleNews_300D', 'mean_sw')\n",
      "('lemmas', 'min', 'GoogleNews_300D', 'idf')\n",
      "('lemmas', 'min', 'GoogleNews_300D', 'idf_sw')\n",
      "('lemmas', 'min', 'Wikipedia_300D', 'mean')\n",
      "('lemmas', 'min', 'Wikipedia_300D', 'mean_sw')\n",
      "('lemmas', 'min', 'Wikipedia_300D', 'idf')\n",
      "('lemmas', 'min', 'Wikipedia_300D', 'idf_sw')\n",
      "('lemmas', 'none', 'Twitter_200D', 'mean')\n",
      "('lemmas', 'none', 'Twitter_200D', 'mean_sw')\n",
      "('lemmas', 'none', 'Twitter_200D', 'idf')\n",
      "('lemmas', 'none', 'Twitter_200D', 'idf_sw')\n",
      "('lemmas', 'none', 'GoogleNews_300D', 'mean')\n",
      "('lemmas', 'none', 'GoogleNews_300D', 'mean_sw')\n",
      "('lemmas', 'none', 'GoogleNews_300D', 'idf')\n",
      "('lemmas', 'none', 'GoogleNews_300D', 'idf_sw')\n",
      "('lemmas', 'none', 'Wikipedia_300D', 'mean')\n",
      "('lemmas', 'none', 'Wikipedia_300D', 'mean_sw')\n",
      "('lemmas', 'none', 'Wikipedia_300D', 'idf')\n",
      "('lemmas', 'none', 'Wikipedia_300D', 'idf_sw')\n",
      "('tokens', 'hour', 'Twitter_200D', 'mean')\n",
      "('tokens', 'hour', 'Twitter_200D', 'mean_sw')\n",
      "('tokens', 'hour', 'Twitter_200D', 'idf')\n",
      "('tokens', 'hour', 'Twitter_200D', 'idf_sw')\n",
      "('tokens', 'hour', 'GoogleNews_300D', 'mean')\n",
      "('tokens', 'hour', 'GoogleNews_300D', 'mean_sw')\n",
      "('tokens', 'hour', 'GoogleNews_300D', 'idf')\n",
      "('tokens', 'hour', 'GoogleNews_300D', 'idf_sw')\n",
      "('tokens', 'hour', 'Wikipedia_300D', 'mean')\n",
      "('tokens', 'hour', 'Wikipedia_300D', 'mean_sw')\n",
      "('tokens', 'hour', 'Wikipedia_300D', 'idf')\n",
      "('tokens', 'hour', 'Wikipedia_300D', 'idf_sw')\n",
      "('tokens', '5min', 'Twitter_200D', 'mean')\n",
      "('tokens', '5min', 'Twitter_200D', 'mean_sw')\n",
      "('tokens', '5min', 'Twitter_200D', 'idf')\n",
      "('tokens', '5min', 'Twitter_200D', 'idf_sw')\n",
      "('tokens', '5min', 'GoogleNews_300D', 'mean')\n",
      "('tokens', '5min', 'GoogleNews_300D', 'mean_sw')\n",
      "('tokens', '5min', 'GoogleNews_300D', 'idf')\n",
      "('tokens', '5min', 'GoogleNews_300D', 'idf_sw')\n",
      "('tokens', '5min', 'Wikipedia_300D', 'mean')\n",
      "('tokens', '5min', 'Wikipedia_300D', 'mean_sw')\n",
      "('tokens', '5min', 'Wikipedia_300D', 'idf')\n",
      "('tokens', '5min', 'Wikipedia_300D', 'idf_sw')\n",
      "('tokens', 'min', 'Twitter_200D', 'mean')\n",
      "('tokens', 'min', 'Twitter_200D', 'mean_sw')\n",
      "('tokens', 'min', 'Twitter_200D', 'idf')\n",
      "('tokens', 'min', 'Twitter_200D', 'idf_sw')\n",
      "('tokens', 'min', 'GoogleNews_300D', 'mean')\n",
      "('tokens', 'min', 'GoogleNews_300D', 'mean_sw')\n",
      "('tokens', 'min', 'GoogleNews_300D', 'idf')\n",
      "('tokens', 'min', 'GoogleNews_300D', 'idf_sw')\n",
      "('tokens', 'min', 'Wikipedia_300D', 'mean')\n",
      "('tokens', 'min', 'Wikipedia_300D', 'mean_sw')\n",
      "('tokens', 'min', 'Wikipedia_300D', 'idf')\n",
      "('tokens', 'min', 'Wikipedia_300D', 'idf_sw')\n",
      "('tokens', 'none', 'Twitter_200D', 'mean')\n",
      "('tokens', 'none', 'Twitter_200D', 'mean_sw')\n",
      "('tokens', 'none', 'Twitter_200D', 'idf')\n",
      "('tokens', 'none', 'Twitter_200D', 'idf_sw')\n",
      "('tokens', 'none', 'GoogleNews_300D', 'mean')\n",
      "('tokens', 'none', 'GoogleNews_300D', 'mean_sw')\n",
      "('tokens', 'none', 'GoogleNews_300D', 'idf')\n",
      "('tokens', 'none', 'GoogleNews_300D', 'idf_sw')\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f.saving_location = 'N:\\\\diplomka temp\\\\dataPickled\\\\Google VW'\n",
    "f.save_VW_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\"\"\"\n",
    "import pickle\n",
    "with open('N:\\\\diplomka temp\\\\dataPickled\\\\dataset_AAPL_BOW', 'rb') as handle:\n",
    "    f = pickle.load(handle)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('N:\\\\diplomka temp\\\\dataPickled\\\\APPL_dataset_object', 'wb') as handle:\n",
    "pickle.dump(f, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
